{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input,Conv2D,Dense,Conv2DTranspose, Reshape,Lambda,LeakyReLU,Flatten,Dropout,Activation\n",
    "from keras.layers.merge import _Merge\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(\n",
    "    self, input_dims,\n",
    "        discriminator_conv_filters,\n",
    "        discriminator_conv_kernel_size,\n",
    "        discriminator_conv_strides,\n",
    "        discriminator_activation,\n",
    "        discriminator_initial_dense_layer_size,\n",
    "        discriminator_dorpout,\n",
    "        discriminator_lr,\n",
    "        generator_initial_dense_layer_size,\n",
    "        generator_unsample,\n",
    "        generator_conv_filters,\n",
    "        generator_conv_kernel_size,\n",
    "        generator_conv_strides,\n",
    "        generator_activation,\n",
    "        generator_dropout,\n",
    "        generator_lr,\n",
    "        optimizier,\n",
    "        latent_dims\n",
    "        \n",
    "    ):\n",
    "        \n",
    "        self.input_dims=input_dims\n",
    "        self.discriminator_conv_filters=discriminator_conv_filters\n",
    "        self.discriminator_conv_kernel_size=discriminator_conv_kernel_size\n",
    "        self.discriminator_conv_strides=discriminator_conv_strides\n",
    "        self.discriminator_activation=discriminator_activation\n",
    "        self.discriminator_initial_dense_layer_size=discriminator_initial_dense_layer_size\n",
    "        self.discriminator_dropout=discriminator_dropout\n",
    "        self.discriminator_lr=discriminator_lr\n",
    "        \n",
    "        self.generator_initial_dense_layer_size=generator_initial_dense_layer_size\n",
    "        self.generator_unsample=generator_unsample\n",
    "        self.generator_conv_filters=generator_conv_filters\n",
    "        self.generator_conv_kernel_size=generator_conv_kernel_size\n",
    "        self.generator_conv_strides=generator_conv_strides\n",
    "        self.generator_activation=generator_activation\n",
    "        self.generator_dropout=generator_dropout\n",
    "        self.generator_lr=generator_lr\n",
    "        self.optimizier=optimizier\n",
    "        self.latent_dims=latent_dims\n",
    "        \n",
    "        self.no_layers_discriminator=len(discriminator_conv_filters)\n",
    "        self.no_layers_generator=len(generator_conv_filters)\n",
    "        \n",
    "        \n",
    "\n",
    "        self.d_loss=[]\n",
    "        self.g_loss=[]\n",
    "        \n",
    "        self._build_discriminator()\n",
    "        self._build_generator()\n",
    "        \n",
    "        \n",
    "    def get_activation(self,activation):\n",
    "        if activation =='leaky_relu':\n",
    "            layer=LeakyRelu(alpha=0.2)\n",
    "        else:\n",
    "            layer=Activation(activation) \n",
    "        return layer\n",
    "    \n",
    "    def _build_discriminator(self):\n",
    "        discriminator_input=Input(shape=self.input_dims,name='discriminator_input')\n",
    "        \n",
    "        x=discriminator_input # I always forget this...everytime, and then have to deal with errors I've never even heard of...I dont know why this happens everytime.\n",
    "        \n",
    "        for i in range(self.no_layers_discriminator):\n",
    "            x=Conv2D(\n",
    "                filters=self.discriminator_conv_filters[i],\n",
    "                kernel_size=self.discriminator_conv_kernel_size[i],\n",
    "                strides=self.discriminator_conv_strides[i],\n",
    "                padding='same',\n",
    "                name='discriminator_layer_'+str(i),\n",
    "\n",
    "                \n",
    "            )(x)\n",
    "            \n",
    "            x=self.get_activation(self.discriminator_activation)(x)\n",
    "            if self.discriminator_dropout:\n",
    "                x=Dropout(rate=self.discriminator_dropout)(x)\n",
    "            x=Flatten(x)\n",
    "            \n",
    "            discriminator_output=Dense(1,activation='sigmoid')(x)\n",
    "            \n",
    "            self.discriminator=Model(discriminator_input,discriminator_output)\n",
    "            \n",
    "            \n",
    "            \n",
    "        def _build_generator(self): #tricky part\n",
    "            # mind the layers\n",
    "            generator_input=Input(shape=(self.latent_dims,),name='generator_input')\n",
    "            #input done\n",
    "            # latent dims -> dense (shape maybe 7*7*64 ?) or np.prod(dense) ? -> reshape? ->connect to generator then...\n",
    "            #input (latent dim size) to dense of number given in input ???\n",
    "            # give the size of dense of generator as ip\n",
    "            # make dense of np.prod(ip)\n",
    "            # connect generator_input to this np.prod(dense) layer\n",
    "            # now try -\n",
    "            #  -- connect this to a smaller dense ?\n",
    "            #  -- connect this to reshape?\n",
    "            #  -- connect directly to unsample ?\n",
    "             \n",
    "                \n",
    "            x= generator_input # dont forget this as I do always\n",
    "            \n",
    "            # trying small dens first, checking working\n",
    "            #x=Dense(512)(x)\n",
    "            \n",
    "            # trying reshape to ip size specified\n",
    "            x=Dense(np.prod(self.generator_initial_dense_layer_size))(x)\n",
    "            x=self.get_activation(self.generator_activation)(x)\n",
    "            \n",
    "            x=Reshape(generator_initial_dense_layer_size)(x)\n",
    "            \n",
    "            if self.generator_dropout:\n",
    "                x=Dropout(sellf.generator_dropout)(x)\n",
    "            # reshape to prod of dims\n",
    "            # connect to dense ? or connect to unsample ?\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ganskernel",
   "language": "python",
   "name": "ganskernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
