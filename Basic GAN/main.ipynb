{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext importnb\n",
    "import GANstructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='../data/camel/full_numpy_bitmap_camel.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_FOLDER='run/'\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.mkdir(RUN_FOLDER)\n",
    "    os.mkdir(os.path.join(RUN_FOLDER,'images'))\n",
    "    os.mkdir(os.path.join(RUN_FOLDER,'weights'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(path):\n",
    "    dataset_size=5000\n",
    "    dataset=np.load(path)\n",
    "    no_of_images=dataset.shape[0]\n",
    "    dataset=dataset.reshape(no_of_images,28,28,1)\n",
    "    dataset=dataset[:dataset_size]\n",
    "    dataset = dataset.astype('float32') / 255.0\n",
    "    '''\n",
    "    test 1\n",
    "    arr = np.arange(10)\n",
    "    np.random.shuffle(arr)\n",
    "    print(arr)\n",
    "    '''\n",
    "    np.random.shuffle(dataset)\n",
    "   \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=loader(path)\n",
    "x=np.squeeze(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x[50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GANstructure.GAN(input_dims = (28,28,1)\n",
    "        , discriminator_conv_filters = [64,64,128,128]\n",
    "        , discriminator_conv_kernel_size = [5,5,5,5]\n",
    "        , discriminator_conv_strides = [2,2,2,1]\n",
    "        , discriminator_activation = 'relu'\n",
    "        , discriminator_dropout = 0.4\n",
    "        , discriminator_lr = 0.0008\n",
    "        , generator_initial_dense_layer_size = (7, 7, 64)\n",
    "        , generator_upsample = [2,2,1,1]\n",
    "        , generator_conv_filters = [128,64, 64,1]\n",
    "        , generator_conv_kernel_size = [5,5,5,5]\n",
    "        , generator_conv_strides = [1,1, 1, 1]\n",
    "        , generator_activation = 'relu'\n",
    "        , generator_dropout = None\n",
    "        , generator_lr = 0.0004\n",
    "        , optimizer = 'rmsprop'\n",
    "        , latent_dims = 100\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "discriminator_input (InputLa (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_layer_0 (Conv2 (None, 14, 14, 64)        1664      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "discriminator_layer_1 (Conv2 (None, 7, 7, 64)          102464    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "discriminator_layer_2 (Conv2 (None, 4, 4, 128)         204928    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "discriminator_layer_3 (Conv2 (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 720,833\n",
      "Trainable params: 720,833\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "generator_input (InputLayer) (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3136)              316736    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_layer_0 (Conv2D)   (None, 14, 14, 128)       204928    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "generator_layer_1 (Conv2D)   (None, 28, 28, 64)        204864    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_layer_2 (Conv2DTra (None, 28, 28, 64)        102464    \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "generator_layer_3 (Conv2DTra (None, 28, 28, 1)         1601      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 830,593\n",
      "Trainable params: 830,593\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 6000\n",
    "PRINT_EVERY_N_BATCHES = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=loader(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=dataset[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latent_dims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-dad7351e4e33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m gan.train(x_train, batch_size = BATCH_SIZE, epochs = EPOCHS, run_folder = RUN_FOLDER, \n\u001b[1;32m----> 2\u001b[1;33m           \u001b[0mprint_every_n_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPRINT_EVERY_N_BATCHES\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Data\\PROG\\Github\\tensorflow\\tensorflow\\Basic GAN\\GANstructure.ipynb\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, x_train, batch_size, epochs, run_folder, print_every_n_batch, using_generator)\u001b[0m\n\u001b[0;32m    258\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_discriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0musing_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m             \u001b[0mg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m             \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"%d [D loss: (%.3f)(R %.3f, F %.3f)] [D acc: (%.3f)(%.3f, %.3f)] [G loss: %.3f] [G acc: %.3f]\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Data\\PROG\\Github\\tensorflow\\tensorflow\\Basic GAN\\GANstructure.ipynb\u001b[0m in \u001b[0;36mtrain_generator\u001b[1;34m(self, batch_size)\u001b[0m\n\u001b[0;32m    251\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m         \u001b[0mvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m         \u001b[0mnoise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlatent_dims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'latent_dims' is not defined"
     ]
    }
   ],
   "source": [
    "gan.train(x_train, batch_size = BATCH_SIZE, epochs = EPOCHS, run_folder = RUN_FOLDER, \n",
    "          print_every_n_batch = PRINT_EVERY_N_BATCHES\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ganskernel",
   "language": "python",
   "name": "ganskernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
